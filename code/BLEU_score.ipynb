{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJAhR_3ji97b",
        "outputId": "3ed17a48-1213-4d4e-875c-df5280725c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyoJTOt2rx8d",
        "outputId": "4957fe84-1363-46ed-d7ba-b2797b10d91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ],
      "source": [
        "pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RdNeVIWhh9Ew"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Willi\\anaconda3\\envs\\adv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.stats import pearsonr\n",
        "import evaluate\n",
        "from torchmetrics import BLEUScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z0Kg1vOkm6Q",
        "outputId": "dcbdbe11-056e-4537-9d83-27d390084dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lXJ4Uw7HpCTw"
      },
      "outputs": [],
      "source": [
        "def get_concordant_discordant_filtered(a, b, min_diff=5):\n",
        "    con = 0\n",
        "    dis = 0\n",
        "\n",
        "    # The LENS paper uses only pairs where all three annotators agree with the ranking order\n",
        "    # and the unnormalised score difference is larger than 5\n",
        "\n",
        "    # If by that, they mean the score difference is larger than 5 for each annotaor:\n",
        "    if False:\n",
        "        for i in range(len(a)):\n",
        "            for j in range(0, i):\n",
        "\n",
        "                # Filter out invalid pairs\n",
        "                filtered = False\n",
        "                for annotator_idx in range(1, 4):\n",
        "                    diff = b.iloc[j][f'rating_{annotator_idx}'] - b.iloc[i][f'rating_{annotator_idx}']\n",
        "\n",
        "                    # Filter out cases where score diff <= 5\n",
        "                    if abs(diff) <= min_diff:\n",
        "                        filtered = True\n",
        "\n",
        "                    # Make sure that all annotators agree with the order\n",
        "                    if annotator_idx == 1:\n",
        "                        larger = diff > 0\n",
        "                    else:\n",
        "                        if (diff > 0) != larger:\n",
        "                            filtered = True\n",
        "                            break\n",
        "                if filtered:\n",
        "                    continue\n",
        "\n",
        "                if larger:\n",
        "                    larger = 1\n",
        "                else:\n",
        "                    larger = -1\n",
        "\n",
        "                # Count concordanct and discordant pairs\n",
        "                if (a[j] - a[i]) * larger > 0:\n",
        "                    con += 1\n",
        "                else:\n",
        "                    dis += 1\n",
        "\n",
        "    # ... If by that, they mean the average score difference is larger than 5:\n",
        "    else:\n",
        "        for i in range(len(a)):\n",
        "            for j in range(0, i):\n",
        "\n",
        "                # Filter\n",
        "                filtered = False\n",
        "                diffs = []\n",
        "                for annotator_idx in range(1, 4):\n",
        "                    diff = b.iloc[j][f'rating_{annotator_idx}'] - b.iloc[i][f'rating_{annotator_idx}']\n",
        "                    diffs.append(diff)\n",
        "\n",
        "                    # Make sure that all annotators agree with the order\n",
        "                    if annotator_idx == 1:\n",
        "                        larger = diff > 0\n",
        "                    else:\n",
        "                        if (diff > 0) != larger:\n",
        "                            filtered = True\n",
        "                            break\n",
        "\n",
        "                # Make sure the average score diff is larger than 5\n",
        "                avg = sum(diffs) / len(diffs)\n",
        "                if abs(avg) <= min_diff:\n",
        "                    filtered = True\n",
        "\n",
        "                if filtered:\n",
        "                    continue\n",
        "\n",
        "                if larger:\n",
        "                    larger = 1\n",
        "                else:\n",
        "                    larger = -1\n",
        "\n",
        "                # Count concordanct and discordant pairs\n",
        "                if (a[j] - a[i]) * larger > 0:\n",
        "                    con += 1\n",
        "                else:\n",
        "                    dis += 1\n",
        "\n",
        "    print(f'Concordant: {con}, discordant: {dis}')\n",
        "    return (con - dis) / (con + dis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "39w9KhqyiAFx"
      },
      "outputs": [],
      "source": [
        "def test_bleu_simpeval_2022():\n",
        "    # Evaluate BLEU's correlation with human scores\n",
        "    # This should correspond to the tao_all value on Table 2 of the LENS paper\n",
        "\n",
        "    # The BLEU implemntation from Huggingface's evaluate package\n",
        "    #bleu = evaluate.load('bleu')\n",
        "    bleu = BLEUScore()\n",
        "\n",
        "    # SimpEval 2022 as provided in the LENS repo\n",
        "    df = pd.read_excel('../data/stage3/simpeval_2022.xlsx')\n",
        "    # df = pd.read_csv(\"../data/stage3/simpeval_2022.csv\")\n",
        "    df_original = copy.deepcopy(df)\n",
        "\n",
        "    human = \"Human 1 Writing\"\n",
        "\n",
        "    # The dataset contains two human simplifications for each source sentence.\n",
        "    # They use one as the reference and the other as the oracle output.\n",
        "    # I use Human 2 Writing as the reference and Human 1 Writing as the oracle output here. I've also tried the other way around.\n",
        "    df = df[df['system'] != human]\n",
        "\n",
        "    scores = []\n",
        "    for i in range(len(df)):\n",
        "        pred = df.iloc[i]['generation']\n",
        "\n",
        "        # Resolve the reference\n",
        "        original_id = df.iloc[i]['original_id']\n",
        "        human_generated = df_original['system'].isin([human])\n",
        "        same_id = df_original['original_id'] == original_id\n",
        "        refs = df_original[human_generated & same_id]['generation'].tolist()\n",
        "\n",
        "        # Compute BLEU under the default settings\n",
        "        #score = bleu.compute(predictions = [pred], references = [refs])['bleu']\n",
        "        #scores.append(score)\n",
        "\n",
        "        bleu.update([pred], [refs])\n",
        "        score = bleu.compute()\n",
        "        score = bleu([pred], [refs])\n",
        "        \n",
        "        if i > 3:\n",
        "            pred = 'Hi I am a sentence'\n",
        "            refs = ['Hi I am a sentence']\n",
        "\n",
        "            bleu.update([pred], [refs])\n",
        "            score = bleu.compute() # This returns a score of 0.1131 probably because the BLEUScore object's states are not properly updated.\n",
        "            print(score)\n",
        "\n",
        "            score = bleu([pred], [refs]) # This returns a score of 1. It is also how the BLEUScore object is used in the documentation: https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html.\n",
        "            print(score)\n",
        "            \n",
        "            print(pred)\n",
        "            print(refs)\n",
        "            break\n",
        "        scores.append(score.item())\n",
        "        #print(score)\n",
        "\n",
        "    #print(scores)\n",
        "    # Kendall tau-like with pairs where all annotators agree with the ranking order and unormalized score differences > 5\n",
        "    kendall = get_concordant_discordant_filtered(scores, df)\n",
        "    print(f'Kendall Tau-like (filtered pairs): {kendall}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsSqpXtDjul2",
        "outputId": "1a66c24f-68c8-4f08-89ac-b16eb0d6c694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1131)\n",
            "tensor(1.)\n",
            "Hi I am a sentence\n",
            "['Hi I am a sentence']\n",
            "Concordant: 0, discordant: 1\n",
            "Kendall Tau-like (filtered pairs): -1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Willi\\anaconda3\\envs\\adv\\lib\\site-packages\\torchmetrics\\text\\bleu.py:74: UserWarning: Input order of targets and preds were changed to predictions firsts and targets second in v0.7. Warning will be removed in v0.8.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "test_bleu_simpeval_2022()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctuRdYRVR1hX",
        "outputId": "f6646911-0ac6-4326-db2c-5258e4b13b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "pred = ['They imposed a fine of $400, or $100 per count of fraud, and three years of supervised release following the prison sentence.']\n",
        "ref = [['The sentence included a three-year supervised release and a fine of $400.']]\n",
        "\n",
        "\n",
        "from torchmetrics import BLEUScore\n",
        "bleu = BLEUScore()\n",
        "\n",
        "my_results = bleu(pred, ref)\n",
        "print(my_results)\n",
        "\n",
        "bleu.update(pred, ref)\n",
        "your_results = bleu.compute()\n",
        "print(your_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
